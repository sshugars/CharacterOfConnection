{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef4772dc-a291-4898-9319-e234dcc94c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# data \n",
    "path = '../../../../data'\n",
    "twitter_path= f'{path}/twitter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6c94c-464c-4852-96ff-17484c314685",
   "metadata": {},
   "source": [
    "# Examine topic distribution in seed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab261ce8-a430-45bc-9b52-e677f0987543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19364162 total seed tweets.\n",
      "  russia: 13868950 (71.62%) tweets\n",
      "  midterms: 5778350 (29.84%) tweets\n",
      "  childcare: 796982 (4.12%) tweets\n",
      "\n",
      "17394543 unique conversation:\n",
      "  midterms: 5315288 (30.56%) conversations\n",
      "  russia: 12318476 (70.82%) conversations\n",
      "  childcare: 764480 (4.39%) conversations\n"
     ]
    }
   ],
   "source": [
    "seed_files = f'{twitter_path}/raw/seed_summaries'\n",
    "\n",
    "topic_counts = dict()\n",
    "tweet_count = 0\n",
    "topic_convos = dict()\n",
    "convo_topics = dict()\n",
    "\n",
    "for filename in glob.glob(f'{seed_files}/*'):\n",
    "    df = pd.read_csv(filename, \n",
    "                     sep='\\t',\n",
    "                     dtype={'tweet_id':str,\n",
    "                            'conversation_id':str})\n",
    "    # conversations\n",
    "    for i, row in df.iterrows():\n",
    "        topics = row['topic'].split('|')\n",
    "        cid = row['conversation_id']\n",
    "        \n",
    "        for topic in topics:\n",
    "            topic = topic.strip()\n",
    "            \n",
    "            # add to topic_convos\n",
    "            topic_convos.setdefault(topic, set())\n",
    "            topic_convos[topic].add(cid)\n",
    "            \n",
    "            # add to convo_topics\n",
    "            convo_topics.setdefault(cid, set())\n",
    "            convo_topics[cid].add(topic)\n",
    "            \n",
    "    # tweets\n",
    "    tweet_count += len(df)\n",
    "    \n",
    "    counts = dict(df['topic'].value_counts())\n",
    "    \n",
    "    for key, value in counts.items():\n",
    "        terms = key.split('|')\n",
    "\n",
    "        for term in terms:\n",
    "            term = term.strip()\n",
    "            topic_counts.setdefault(term, 0)\n",
    "            topic_counts[term] += value\n",
    "\n",
    "# Tweets\n",
    "print(f'{tweet_count} total seed tweets.')\n",
    "\n",
    "for topic, count in topic_counts.items():\n",
    "    print(f'  {topic}: {count} ({count/tweet_count:.2%}) tweets') \n",
    "    \n",
    "# Conversations\n",
    "total_convos = len(convo_topics)\n",
    "print(f'\\n{total_convos} unique conversation:')\n",
    "\n",
    "for topic, cids in topic_convos.items():\n",
    "    print(f'  {topic}: {len(cids)} ({len(cids)/total_convos :.2%}) conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08281d7b-dc4e-479e-9874-72090bf1512a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to topic-to-convo dict to file...\n",
      "\tTopic-to-convo dict written to file\n",
      "Writing convo-to-topic dict to file...\n",
      "\tConvo-to-topic dict written to file\n"
     ]
    }
   ],
   "source": [
    "# write to file\n",
    "outfile = f'{twitter_path}/reference/twitter_seed_topic_convo.json'\n",
    "\n",
    "topic_convos_json = dict((topic, list(cids)) for topic, cids in topic_convos.items())\n",
    "print('Writing to topic-to-convo dict to file...')\n",
    "\n",
    "with open(outfile, 'w') as fp:\n",
    "    fp.write(json.dumps(topic_convos_json))\n",
    "    \n",
    "print('\\tTopic-to-convo dict written to file')\n",
    "\n",
    "outfile = f'{twitter_path}/reference/twitter_seed_convo_topic.json'\n",
    "\n",
    "convos_topic_json = dict((cid, list(topics)) for cid, topics in convo_topics.items())\n",
    "print('Writing convo-to-topic dict to file...')\n",
    "\n",
    "with open(outfile, 'w') as fp:\n",
    "    fp.write(json.dumps(convos_topic_json))\n",
    "    \n",
    "print('\\tConvo-to-topic dict written to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ed424-62d0-43e1-9b36-84295c6be833",
   "metadata": {},
   "source": [
    "# Check conversations searched with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "680df104-ebc5-4421-8a1e-b073cad4ac41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_convo_path = f'{twitter_path}/raw/conversation_errors'\n",
    "no_convos_file = f'{twitter_path}/reference/no_convos.txt'\n",
    "\n",
    "for i, filename in enumerate(glob.glob(f'{no_convo_path}/*')):\n",
    "    convo_id = filename.split('/')[-1].split('_')[0]\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(filename, 'r') as fp:\n",
    "            data = json.loads(fp.read())\n",
    "            \n",
    "        if 'meta' in data:\n",
    "            if data['meta']['result_count'] == 0:\n",
    "                with open(no_convos_file, 'a') as fp:\n",
    "                    fp.write(convo_id + '\\n')\n",
    "                    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6f61775-eb25-49bd-92f2-fac90c0444f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1362875 conversation ids returned no conversations\n",
      "  midterms: 172929 (12.69%) conversations\n",
      "  russia: 584404 (42.88%) conversations\n",
      "  childcare: 25726 (1.89%) conversations\n"
     ]
    }
   ],
   "source": [
    "no_convos = set()\n",
    "\n",
    "with open(no_convos_file, 'r') as fp:\n",
    "    for line in fp.readlines():\n",
    "        convo_id = line.strip()\n",
    "        no_convos.add(convo_id)\n",
    "        \n",
    "print(f'{len(no_convos)} conversation ids returned no conversations')\n",
    "\n",
    "# check distribution by topic\n",
    "for topic, cids in topic_convos.items():\n",
    "    topic_no_convo = no_convos.intersection(cids)\n",
    "\n",
    "    print(f'  {topic}: {len(topic_no_convo)} ({len(topic_no_convo)/len(no_convos) :.2%}) conversations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167a796-164b-439f-b941-14e8ecc0420a",
   "metadata": {},
   "source": [
    "# Check collected conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba749336-e5e8-4273-8a05-f6503e134b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113966 conversations collected.\n",
      "  midterms: 23972 (21.03%) conversations\n",
      "  russia: 51720 (45.38%) conversations\n",
      "  childcare: 3086 (2.71%) conversations\n"
     ]
    }
   ],
   "source": [
    "collected_convo_path = f'{twitter_path}/conversation_tables'\n",
    "\n",
    "collected = set()\n",
    "\n",
    "for filename in glob.glob(f'{collected_convo_path}/*'):\n",
    "    conversation_id = filename.split('/')[-1].split('.')[0]\n",
    "    collected.add(conversation_id)\n",
    "    \n",
    "print(f'{len(collected)} conversations collected.')\n",
    "\n",
    "# check distribution by topic\n",
    "for topic, cids in topic_convos.items():\n",
    "    topic_collected = collected.intersection(cids)\n",
    "\n",
    "    print(f'  {topic}: {len(topic_collected)} ({len(topic_collected)/len(collected) :.2%}) conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675ff40-79d4-4b3c-8d19-1483150711b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a10abf-6eca-42f4-9c9b-85c9f9630d6a",
   "metadata": {},
   "source": [
    "# Full breakdown of search by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79de1f46-4f8f-44f1-829d-e2ac124fc8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17394543 conversation in seed tweets.\n",
      "\n",
      "**** midterms ****\n",
      "   Total conversations: 5315288\n",
      "   Found with data 23972 (0.45%)\n",
      "   Found with no data 172929 (3.25%)\n",
      "   196894 (3.70%) conversations already searched.\n",
      "   5118394 (96.30%) conversations remaining to be searched for topic midterms\n",
      "**** russia ****\n",
      "   Total conversations: 12318476\n",
      "   Found with data 51720 (0.42%)\n",
      "   Found with no data 584404 (4.74%)\n",
      "   636112 (5.16%) conversations already searched.\n",
      "   11682364 (94.84%) conversations remaining to be searched for topic russia\n",
      "**** childcare ****\n",
      "   Total conversations: 764480\n",
      "   Found with data 3086 (0.40%)\n",
      "   Found with no data 25726 (3.37%)\n",
      "   28809 (3.77%) conversations already searched.\n",
      "   735671 (96.23%) conversations remaining to be searched for topic childcare\n"
     ]
    }
   ],
   "source": [
    "remaining_dict = dict()\n",
    "\n",
    "print(f'{total_convos} conversation in seed tweets.\\n')\n",
    "\n",
    "for topic, convo_list in topic_convos.items():\n",
    "    print(f'**** {topic} ****')\n",
    "    \n",
    "    n = len(convo_list)\n",
    "    \n",
    "    print(f'   Total conversations: {len(convo_list)}')\n",
    "    \n",
    "    # conversations found\n",
    "    overlap_data = convo_list.intersection(collected)\n",
    "    \n",
    "    # conversations searched but not found\n",
    "    overlap_no_data = convo_list.intersection(no_convos)\n",
    "    \n",
    "    print(f'   Found with data {len(overlap_data)} ({len(overlap_data)/n :.2%})')\n",
    "    print(f'   Found with no data {len(overlap_no_data)} ({len(overlap_no_data)/n :.2%})')\n",
    "    \n",
    "    total = overlap_data.union(overlap_no_data)\n",
    "    print(f'   {len(total)} ({len(total)/n:.2%}) conversations already searched.')\n",
    "    \n",
    "    remaining = convo_list.difference(total)\n",
    "    print(f'   {len(remaining)} ({len(remaining)/n:.2%}) conversations remaining to be searched for topic {topic}')\n",
    "    \n",
    "    # save ids to search\n",
    "    remaining_dict[topic] = list(remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c83daf9-6e05-4029-ae35-12ec034990e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation ids which have not been searched written to file\n"
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "with open(f'{twitter_path}/reference/convos_not_searched.json', 'w') as fp:\n",
    "    fp.write(json.dumps(remaining_dict))\n",
    "    \n",
    "print(f'Conversation ids which have not been searched written to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6579efe-79b1-48ed-b885-19289267226e",
   "metadata": {},
   "source": [
    "# Sample additional conversations to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c4f1179-8a55-4055-89f9-0e6eba32f750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 68871 conversations for midterms\n",
      "No additional conversations needed for russia\n",
      "Searching 9416 conversations for childcare\n",
      "\n",
      "Searching 78279 conversations overall.\n",
      "Conversation ids written to file.\n"
     ]
    }
   ],
   "source": [
    "search = set()\n",
    "\n",
    "for topic, convo_list in topic_convos.items():\n",
    "    \n",
    "    # ideal final sample size\n",
    "    final_sample_size = int(len(convo_list) * 0.05) + 1\n",
    "    \n",
    "    #### searched conversations\n",
    "    # conversations found\n",
    "    overlap_data = convo_list.intersection(collected)\n",
    "    \n",
    "    # conversations searched but not found\n",
    "    overlap_no_data = convo_list.intersection(no_convos)\n",
    "    \n",
    "    searched = len(overlap_data.union(overlap_no_data))\n",
    "    \n",
    "    # remaining sample needed\n",
    "    sample_size = final_sample_size - searched \n",
    "\n",
    "    if sample_size > 0:\n",
    "        # set of unsearched convos (we will sample from here)\n",
    "        remaining = remaining_dict[topic]\n",
    "\n",
    "        sample = random.sample(remaining, sample_size)\n",
    "\n",
    "        search.update(set(sample))\n",
    "\n",
    "        print(f'Searching {len(sample)} conversations for {topic}')\n",
    "    else:\n",
    "        print(f'No additional conversations needed for {topic}')\n",
    "\n",
    "print(f'\\nSearching {len(search)} conversations overall.')\n",
    "\n",
    "# write to file\n",
    "with open(f'{twitter_path}/reference/twitter_convos_to_search.txt', 'w') as fp:\n",
    "    for cid in search:\n",
    "        fp.write(cid + '\\n')\n",
    "        \n",
    "print('Conversation ids written to file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98c871-cb80-4545-a356-8bd8a555a155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc872306-2657-457d-9924-6ef20f762722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c78be-b86d-40da-b5ac-3f57697c59f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
